---
title: "Navigating Belief Bubbles in the Age of Information"
author: Shyam Sunder
date: "2026-02-19"
categories: [Writing]
tags: [artilce, philosophy]
layout: post
image: assets/belief_bubble.jpg
---



How many times have you had a heated discussion with your friend or colleague and felt like they have been brainwashed? How many times have you been left frustrated thinking why the other person is so unaware of social injustice? Why are they being such an _andhbhakt_? And how many times have you thought that it might have been you who has been brainwashed?

## What are belief bubbles?

Before we start discussing belief bubbles, I want to talk about _conformation bias_. It's a known fact that we tend to seek the information which aligns with our existing beliefs and ignore the facts that go directly against them. This is called conformation bias. For example, when we come across something good about the ruling party, we genuinely believe it; however, if something against it pops up, we tend to dismiss it, saying it’s propaganda from the opposition. 

We tend to mingle more with people who share our beliefs and distance ourselves from those who don't. And if we find something that directly challenges our preexisting norm, we become uncomfortable. This is called cognitive dissonance (this might not be the correct definition. Psychologists, please spare me.) 

Social media algorithms amplify the conformation bias. These platforms are designed to maximise the time you spend on them. And in doing so, they detect your beliefs by your interactions, and after that, they will only show content that aligns with your belief system, so that you engage with it more. It filters out the information that might cause cognitive dissonance and mental discomfort when dealing with it. So it is also named **Filter Bubble** sometimes. 

>your filter bubble is your own personal, unique universe of information that you live in online. And what’s in your filter bubble depends on who you are, and it depends on what you do. But the thing is that you don’t decide what gets in. And more importantly, you don’t actually see what gets edited out.
> 
>~ Eli Pariser, Beware online: Filter Bubbles

After continuous exposure to such content, your beliefs become stronger and stronger. For example, if you believe that the government is bad, then your feed will only show you bad things about the government, and you will be convinced that the government can never do anything wrong, and vice versa. It can take your beliefs from mild interest to extremes in a matter of reels. 

The impact is severe on a mass scale. If the whole of a community is addicted to content consumption on social media, then society will become polarised very soon. 

## The Problem with belief bubbles
- **Overestimation of the prevalence of our beliefs and losing grip on reality** is one of the most visible effects on these belief bubbles. Especially when people aren't aware of the algorithm, they will think that everyone _actually_ thinks in the same way. Which makes them feel like their beliefs are more prominent than they actually are. 
>In addition, one of the biggest issues of filter bubbles is they are invisible, and people don’t realize that they are seeing something different than everyone else. This leads them to believe that their opinion must be right, because all they see is their side and they assume everyone else is seeing that too.
>
>~[Kristen Allred](https://medium.com/@10797952?source=post_page---byline--df6c5cbf919f---------------------------------------)
- Once a person said to me that the government is going to shut down schools and make education online for everyone because in every other school, a teacher is accused of sexual harassment. It made me sad beyond words. 
> The term _Doom Scrolling_ is related to the _Doomsday Effect_. People who click more on negative news are shown more negative news and eventually become convinced that doomsday is coming. 
- Polarisation & Lack of empathy. Filter bubbles communicated through social media can result in polarisation because the beliefs of people will be taken to the extreme. But the even more dangerous impact is that it can propagate the 'us' vs 'them' formalism. It will widen the gap between 'us' and them which can result in dangerous consequences. 
- **A narrower viewpoint prevents us from gaining new knowledge**. Social media is designed to show us only one side of the coin which can never be the whole and true knowledge. The reels from the opposite side make us feel uncomfortable and we tend to ignore and skip them rather than take the effort to analyse and gather knowledge from them.

## How to navigate belief bubbles without being 'brainwashed'
- **First, you should voluntarily expose yourself to the contrary belief**. If you are an atheist, then you should unfollow your favourite creators and start listening to the arguments from people like William Lane Craig. These arguments are going to make you uncomfortable, but instead of skipping over or laughing it off. You should really put your beliefs to the test. You should defend your conventions and try to come up with counterarguments. I again want to paraphrase Derek Muller, paraphrasing Popper:
> The only way to prove something is to try as hard as you can to disprove it.
- My friend [Vinod Jiani](https://vkj-here.blogspot.com) once told me that to make sure he doesn't fall into fanboy culture, he tries to read criticism of the author he likes the most. At the time, he was reading why Yuvalian’s narrative of history is problematic. I think we all should try to find flaws in our heroes. 
- I think that we should try to **consume knowledge in its rawest form**. This way, we can eliminate the fight on interpretation and come up with our own strongly backed belief. Which means that instead of consuming content on social media, we should read books, reports, and documentaries, do our own research to gain knowledge. Instead of watching popular God-debunked-with-science videos, we should take university courses on religious philosophy. And read the god-damned scriptures. 
- We should participate more in debates and try to gain knowledge through dialogues (which is called _The Socratic Method_). But we shouldn't enter a debate trying to win the argument but trying to learn something from the other person. It's highly unlikely that a debate might change your perspective, but we should observe ourselves if we are able to come up with counterarguments and defend our beliefs. It will show us if they are strongly rooted. And hence we can burst the belief bubble. 
- My best advice is don't use social media. Stay away from it. Enjoy your life offline. 

## Conclusion

It is said that a life unexamined is a life not worth living. As a professional rest-framer, I often think about how we can understand different frames of reference better. And my personal experience is that the filter bubble from social media makes us lean towards one point of view and hold others. But as an AI enthusiast, I know how these things work and I know that they can be altered to fit my choices. Filter bubbles are dangerous and they have dangerous consequences, but just knowing that they exist is one big caution to make sure that you won't fall for them. And I have tried to achieve that in my post. 
## References 

- [Beware online "filter bubbles" - Eli Pariser](https://www.youtube.com/watch?v=B8ofWFx525s)
- [The Problem With Social Media Reinforcement Bubbles](https://longevitygains.com/belief-bubbles-how-to-avoid-the-worldview-backfire-effect/)
- [How Filter Bubbles are biasing your opinions of social media](https://medium.com/data-and-beyond/how-filter-bubbles-are-biasing-your-opinions-on-social-media-9469b940154)
- [Study on existence of filter bubbles in modern recommendation systems.](https://arxiv.org/html/2307.01221)
- [The Causes and Effects of “Filter Bubbles” and how to Break Free￼](https://medium.com/@10797952/the-causes-and-effects-of-filter-bubbles-and-how-to-break-free-df6c5cbf919f)
